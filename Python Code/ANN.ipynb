{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ub47arBf9bd",
        "outputId": "477c07cf-5f6e-4a42-e873-29d6a5c847b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "606/606 [==============================] - 1s 1ms/step\n",
            "\n",
            "ANN Results:\n",
            "Accuracy: 0.9496439995872459\n",
            "\n",
            "Confusion Matrix:\n",
            "[[15963   342     0     0     0     0     0     0     0]\n",
            " [   98  2443     0     0     0     0     0     0     0]\n",
            " [    0   419     0     0     0     0     0     0     0]\n",
            " [    0    89     0     0     0     0     0     0     0]\n",
            " [    0    19     0     0     0     0     0     0     0]\n",
            " [    0     6     0     0     0     0     0     0     0]\n",
            " [    0     1     0     0     0     0     0     0     0]\n",
            " [    0     1     0     0     0     0     0     0     0]\n",
            " [    0     1     0     0     0     0     0     0     0]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99     16305\n",
            "           1       0.74      0.96      0.83      2541\n",
            "           2       1.00      0.00      0.00       419\n",
            "           3       1.00      0.00      0.00        89\n",
            "           4       1.00      0.00      0.00        19\n",
            "           5       1.00      0.00      0.00         6\n",
            "           7       1.00      0.00      0.00         1\n",
            "           8       1.00      0.00      0.00         1\n",
            "           9       1.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.95     19382\n",
            "   macro avg       0.97      0.22      0.20     19382\n",
            "weighted avg       0.96      0.95      0.94     19382\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "import warnings\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'output_dataset.csv'  # Replace 'your_dataset.csv' with the actual file path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Drop non-numeric columns that are not needed for prediction\n",
        "df = df.drop(['DayOfWeek', 'Date', 'UniqueCarrier', 'Airline', 'FlightNum', 'TailNum', 'Origin', 'Org_Airport', 'Dest', 'Dest_Airport', 'Cancelled', 'CancellationCode', 'Diverted'], axis=1)\n",
        "\n",
        "# Define range-specific encoding function with 10 partitions\n",
        "def range_encoding(value):\n",
        "    if value <= 100:\n",
        "        return '0-100'\n",
        "    elif 101 <= value <= 200:\n",
        "        return '101-200'\n",
        "    elif 201 <= value <= 300:\n",
        "        return '201-300'\n",
        "    elif 301 <= value <= 400:\n",
        "        return '301-400'\n",
        "    elif 401 <= value <= 500:\n",
        "        return '401-500'\n",
        "    elif 501 <= value <= 600:\n",
        "        return '501-600'\n",
        "    elif 601 <= value <= 700:\n",
        "        return '601-700'\n",
        "    elif 701 <= value <= 800:\n",
        "        return '701-800'\n",
        "    elif 801 <= value <= 900:\n",
        "        return '801-900'\n",
        "    else:\n",
        "        return '901-1000'\n",
        "\n",
        "# Apply range-specific encoding to 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay', and 'ArrDelay'\n",
        "for col in ['CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay', 'ArrDelay']:\n",
        "    df[col] = df[col].apply(range_encoding)\n",
        "\n",
        "# Convert categorical variables to numeric using Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "for col in ['CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay', 'ArrDelay']:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = df.drop('ArrDelay', axis=1)\n",
        "y = df['ArrDelay']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Suppress ConvergenceWarnings\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "# Create and train the ANN model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=0)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int).reshape(-1)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred, zero_division=1)\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nANN Results:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)\n",
        "\n",
        "# Re-enable warnings after fitting the model\n",
        "warnings.resetwarnings()\n"
      ]
    }
  ]
}